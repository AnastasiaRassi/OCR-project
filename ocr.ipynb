{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e284dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aceebbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd =r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2389b91",
   "metadata": {},
   "source": [
    "# Full OCR Pipeline: Automated text extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937f0c6a",
   "metadata": {},
   "source": [
    "* Image loading from folder\n",
    "* Preprocessing: Adaptive Thresholding, Morphological opening and closing, Upscaling, Sharpening\n",
    "* Text Extraction (Tesseract)\n",
    "* Postprocessing: Cleaning the extracted text\n",
    "* Storing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62f611a",
   "metadata": {},
   "source": [
    "### 1. I will make my CV PDF into images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9fccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "\n",
    "pdf_path = \"C:/Users/aalrassi/Documents/anastasia_learning/DL_indep/OCR_Project/Data Science CV.pdf\"        \n",
    "image_folder = \"samples\"  \n",
    "os.makedirs(image_folder, exist_ok=True)\n",
    "\n",
    "poppler_path =\"C:/Users/aalrassi/Downloads/Release-25.07.0-0/poppler-25.07.0/Library/bin\"\n",
    "\n",
    "pages = convert_from_path(pdf_path, dpi=300, poppler_path=poppler_path)\n",
    "for i, page in enumerate(pages):\n",
    "    image_path = os.path.join(image_folder, f\"cv_page{i+1}.png\")\n",
    "    page.save(image_path, \"PNG\")\n",
    "    print(f\"Saved {image_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79ade97",
   "metadata": {},
   "source": [
    "### 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a603cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "results_folder = \"results\"\n",
    "os.makedirs(results_folder, exist_ok=True)  # creates folder if it doesn't exist\n",
    "\n",
    "output_csv = os.path.join(results_folder, \"cv_text.csv\")\n",
    "def preprocess_image(img_path):\n",
    "    # Load image in color\n",
    "    img = cv2.imread(img_path)\n",
    "    \n",
    "    # Resize only if width < 1200px\n",
    "    h, w = img.shape[:2]\n",
    "    target_width = 1200\n",
    "    if w < target_width:\n",
    "        scale = target_width / w\n",
    "        img = cv2.resize(img, (target_width, int(h * scale)), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Sharpening\n",
    "    kernel = np.array([[0, -1, 0],\n",
    "                       [-1, 5, -1],\n",
    "                       [0, -1, 0]])\n",
    "    img = cv2.filter2D(img, -1, kernel)\n",
    "    \n",
    "    # Convert to grayscale for adaptive thresholding\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Adaptive thresholding (Gaussian)\n",
    "    preprocessed_img = cv2.adaptiveThreshold(\n",
    "        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, 8\n",
    "    )\n",
    "    kernel = np.ones((2,2), np.uint8)\n",
    "\n",
    "    return preprocessed_img\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924dbf2a",
   "metadata": {},
   "source": [
    "* Text extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19b6b5d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Save results to CSV\u001b[39;00m\n\u001b[0;32m     18\u001b[0m output_csv \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(results_folder, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv_text_easyocr.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 19\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mocr_results\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(output_csv, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOCR results saved to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moutput_csv\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\aalrassi\\Documents\\anastasia_learning\\DL_indep\\.venv\\lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\aalrassi\\Documents\\anastasia_learning\\DL_indep\\.venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\aalrassi\\Documents\\anastasia_learning\\DL_indep\\.venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:114\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 114\u001b[0m         index \u001b[38;5;241m=\u001b[39m \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    116\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mc:\\Users\\aalrassi\\Documents\\anastasia_learning\\DL_indep\\.venv\\lib\\site-packages\\pandas\\core\\internals\\construction.py:667\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    664\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    666\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m--> 667\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_series:\n\u001b[0;32m    670\u001b[0m     index \u001b[38;5;241m=\u001b[39m union_indexes(indexes)\n",
      "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "import easyocr, pandas as pd,csv\n",
    "\n",
    "ocr_results = {}\n",
    "\n",
    "# Process all images in folder\n",
    "for filename in sorted(os.listdir(image_folder)):\n",
    "    if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        img_path = os.path.join(image_folder, filename)\n",
    "        preprocessed_img = preprocess_image(img_path)\n",
    "        \n",
    "        # Convert OpenCV image to PIL image\n",
    "        pil_img = Image.fromarray(preprocessed_img)\n",
    "        \n",
    "        # OCR\n",
    "        text = pytesseract.image_to_string(pil_img, config='--psm 3')\n",
    "        ocr_results[filename] = text\n",
    "\n",
    "# Save results to CSV\n",
    "output_csv = os.path.join(results_folder, \"cv_text.csv\")\n",
    "with open(output_csv, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Page\", \"Extracted_Text\"])\n",
    "    for page, text in ocr_results.items():\n",
    "        writer.writerow([page, text])\n",
    "\n",
    "print(f\"OCR completed. Results saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90e0f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved preprocessed image: preprocessed_images\\cv_page1.png\n",
      "Saved preprocessed image: preprocessed_images\\cv_page2.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "preprocessed_folder = \"preprocessed_images\"\n",
    "os.makedirs(preprocessed_folder, exist_ok=True)\n",
    "\n",
    "for filename in sorted(os.listdir(\"samples\")):\n",
    "    if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        img_path = os.path.join(\"samples\", filename)  # Correct folder\n",
    "        preprocessed_img = preprocess_image(img_path)\n",
    "        \n",
    "        # Save preprocessed image\n",
    "        save_path = os.path.join(preprocessed_folder, filename)\n",
    "        cv2.imwrite(save_path, preprocessed_img)\n",
    "        print(f\"Saved preprocessed image: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc83232",
   "metadata": {},
   "source": [
    "### Checking accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e0ea08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall OCR Accuracy: 48.72%\n",
      "Page 1 accuracy: 52.38%\n",
      "Page 2 accuracy: 43.74%\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein\n",
    "import pandas as pd\n",
    "\n",
    "# Load OCR and ground-truth CSVs\n",
    "ocr_df = pd.read_csv(r'results/cv_text.csv')\n",
    "gt_df = pd.read_csv(r'results/true_text.csv')\n",
    "\n",
    "# Combine all pages into a single string\n",
    "ocr_text = \" \".join(ocr_df['Extracted_Text'].astype(str))\n",
    "gt_text = \" \".join(gt_df['Extracted_Text'].astype(str))\n",
    "\n",
    "# Compute overall character-level accuracy\n",
    "accuracy = (1 - Levenshtein.distance(ocr_text, gt_text)/len(gt_text)) * 100\n",
    "print(f\"Overall OCR Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Optional: per-page accuracy\n",
    "for i, (ocr, gt) in enumerate(zip(ocr_df['Extracted_Text'], gt_df['Extracted_Text']), 1):\n",
    "    page_acc = (1 - Levenshtein.distance(str(ocr), str(gt))/len(str(gt))) * 100\n",
    "    print(f\"Page {i} accuracy: {page_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42415202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page</th>\n",
       "      <th>Extracted_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv_page1.png</td>\n",
       "      <td>CONTACT\\nMobile: +961 81 393 583\\n\\nGmail: ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv_page2.png</td>\n",
       "      <td>SKILLS\\n\\nFluent in English and Arabic,\\nwith ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Page                                     Extracted_Text\n",
       "0  cv_page1.png  CONTACT\\nMobile: +961 81 393 583\\n\\nGmail: ana...\n",
       "1  cv_page2.png  SKILLS\\n\\nFluent in English and Arabic,\\nwith ..."
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1616c0fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7003ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
