{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e284dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pytesseract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aceebbd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytesseract.pytesseract.tesseract_cmd =r\"C:\\Program Files\\Tesseract-OCR\\tesseract.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2389b91",
   "metadata": {},
   "source": [
    "# Full OCR Pipeline: Automated text extraction "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937f0c6a",
   "metadata": {},
   "source": [
    "* Image loading from folder\n",
    "* Preprocessing: Adaptive Thresholding, Morphological opening and closing, Upscaling, Sharpening\n",
    "* Text Extraction (Tesseract)\n",
    "* Postprocessing: Cleaning the extracted text\n",
    "* Storing Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62f611a",
   "metadata": {},
   "source": [
    "### 1. I will make my CV PDF into images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f9fccd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved samples\\cv_page1.png\n",
      "Saved samples\\cv_page2.png\n"
     ]
    }
   ],
   "source": [
    "from pdf2image import convert_from_path\n",
    "import os\n",
    "\n",
    "pdf_path = \"C:/Users/aalrassi/Documents/anastasia_learning/DL_indep/OCR_Project/Data Science CV.pdf\"        \n",
    "image_folder = \"samples\"  \n",
    "os.makedirs(image_folder, exist_ok=True)\n",
    "\n",
    "poppler_path =\"C:/Users/aalrassi/Downloads/Release-25.07.0-0/poppler-25.07.0/Library/bin\"\n",
    "\n",
    "pages = convert_from_path(pdf_path, dpi=300, poppler_path=poppler_path)\n",
    "for i, page in enumerate(pages):\n",
    "    image_path = os.path.join(image_folder, f\"cv_page{i+1}.png\")\n",
    "    page.save(image_path, \"PNG\")\n",
    "    print(f\"Saved {image_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c79ade97",
   "metadata": {},
   "source": [
    "### 2. Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a603cf19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "results_folder = \"results\"\n",
    "os.makedirs(results_folder, exist_ok=True)  # creates folder if it doesn't exist\n",
    "\n",
    "output_csv = os.path.join(results_folder, \"cv_text.csv\")\n",
    "def preprocess_image(img_path):\n",
    "    # Load image in color\n",
    "    img = cv2.imread(img_path)\n",
    "    h, w = img.shape[:2]\n",
    "\n",
    "    # Resize only if width < 1200px\n",
    "    target_width = 1200\n",
    "    if w < target_width:\n",
    "        scale = target_width / w\n",
    "        img = cv2.resize(img, (target_width, int(h * scale)), interpolation=cv2.INTER_CUBIC)\n",
    "    \n",
    "    # Sharpening\n",
    "    kernel = np.array([[0, -1, 0],\n",
    "                       [-1, 5, -1],\n",
    "                       [0, -1, 0]])\n",
    "    img = cv2.filter2D(img, -1, kernel)\n",
    "    \n",
    "    # Convert to grayscale for adaptive thresholding\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    # Adaptive thresholding (Gaussian)\n",
    "    preprocessed_img = cv2.adaptiveThreshold(\n",
    "        gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 15, 8\n",
    "    )\n",
    "    # kernel = np.ones((3, 3), np.uint8)\n",
    "    # preprocessed_img = cv2.morphologyEx(preprocessed_img, cv2.MORPH_CLOSE, kernel)\n",
    "    return preprocessed_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bb4272",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0283d541",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "924dbf2a",
   "metadata": {},
   "source": [
    "* Text extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d19b6b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OCR completed. Results saved to results\\cv_text.csv\n"
     ]
    }
   ],
   "source": [
    "import easyocr, pandas as pd,csv\n",
    "\n",
    "ocr_results = {}\n",
    "\n",
    "# Process all images in folder\n",
    "for filename in sorted(os.listdir(image_folder)):\n",
    "    if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        img_path = os.path.join(image_folder, filename)\n",
    "        preprocessed_img = preprocess_image(img_path)\n",
    "        \n",
    "        # Convert OpenCV image to PIL image\n",
    "        pil_img = Image.fromarray(preprocessed_img)\n",
    "        \n",
    "        # OCR\n",
    "        text = pytesseract.image_to_string(pil_img, config='--psm 3')\n",
    "        ocr_results[filename] = text\n",
    "\n",
    "# Save results to CSV\n",
    "output_csv = os.path.join(results_folder, \"cv_text.csv\")\n",
    "with open(output_csv, mode=\"w\", newline=\"\", encoding=\"utf-8\") as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Page\", \"Extracted_Text\"])\n",
    "    for page, text in ocr_results.items():\n",
    "        writer.writerow([page, text])\n",
    "\n",
    "print(f\"OCR completed. Results saved to {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e90e0f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved preprocessed image: preprocessed_images\\cv_page1.png\n",
      "Saved preprocessed image: preprocessed_images\\cv_page2.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "\n",
    "preprocessed_folder = \"preprocessed_images\"\n",
    "os.makedirs(preprocessed_folder, exist_ok=True)\n",
    "\n",
    "for filename in sorted(os.listdir(\"samples\")):\n",
    "    if filename.lower().endswith((\".png\", \".jpg\", \".jpeg\")):\n",
    "        img_path = os.path.join(\"samples\", filename)  # Correct folder\n",
    "        preprocessed_img = preprocess_image(img_path)\n",
    "        \n",
    "        # Save preprocessed image\n",
    "        save_path = os.path.join(preprocessed_folder, filename)\n",
    "        cv2.imwrite(save_path, preprocessed_img)\n",
    "        print(f\"Saved preprocessed image: {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc83232",
   "metadata": {},
   "source": [
    "### Checking accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0e0ea08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall OCR Accuracy: 84.74%\n",
      "Page 1 accuracy: 94.95%\n",
      "Page 2 accuracy: 75.39%\n"
     ]
    }
   ],
   "source": [
    "import Levenshtein\n",
    "import pandas as pd\n",
    "\n",
    "# Load OCR and ground-truth CSVs\n",
    "ocr_df = pd.read_csv(r'results/cv_text.csv')\n",
    "gt_df = pd.read_csv(r'results/true_text.csv')\n",
    "\n",
    "# Combine all pages into a single string\n",
    "ocr_text = \" \".join(ocr_df['Extracted_Text'].astype(str))\n",
    "gt_text = \" \".join(gt_df['Extracted_Text'].astype(str))\n",
    "\n",
    "# Compute overall character-level accuracy\n",
    "accuracy = (1 - Levenshtein.distance(ocr_text, gt_text)/len(gt_text)) * 100\n",
    "print(f\"Overall OCR Accuracy: {accuracy:.2f}%\")\n",
    "\n",
    "# Optional: per-page accuracy\n",
    "for i, (ocr, gt) in enumerate(zip(ocr_df['Extracted_Text'], gt_df['Extracted_Text']), 1):\n",
    "    page_acc = (1 - Levenshtein.distance(str(ocr), str(gt))/len(str(gt))) * 100\n",
    "    print(f\"Page {i} accuracy: {page_acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "42415202",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page</th>\n",
       "      <th>Extracted_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cv_page1.png</td>\n",
       "      <td>CONTACT\\nMobile: +961 81 393 583\\n\\nGmail: ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cv_page2.png</td>\n",
       "      <td>SKILLS\\n\\nFluent in English and Arabic,\\nwith ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Page                                     Extracted_Text\n",
       "0  cv_page1.png  CONTACT\\nMobile: +961 81 393 583\\n\\nGmail: ana...\n",
       "1  cv_page2.png  SKILLS\\n\\nFluent in English and Arabic,\\nwith ..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ocr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7003ffa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
